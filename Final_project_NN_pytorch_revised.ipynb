{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final project_NN_pytorch_revised.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YiFeng/Final_2020-Fall_NN/blob/main/Final_project_NN_pytorch_revised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spLGkahHNLUK"
      },
      "source": [
        "# Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y2QXQuU2gD_"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os.path as path\n",
        "import seaborn as sns\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tRBCOyB2ohj"
      },
      "source": [
        "# load and preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go7Vd5A-kGP9"
      },
      "source": [
        "load data and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h563NiMZ6pQ6",
        "outputId": "dfa5d9bd-e756-457d-e260-f5cac3740f58"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04rhFpUSXNUR"
      },
      "source": [
        "# load data\n",
        "work_dir: str = '/content/drive/My Drive/Yi_UCI_courses/2020 Fall/NN'\n",
        "feature: pd.DataFrame = pd.read_csv(path.join(work_dir, 'features.csv'))\n",
        "performance_10session: pd.DataFrame = pd.read_csv(path.join(work_dir, 'results_10session.csv'))\n",
        "feature_name_list: List[str] = list(feature.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s3Inf-1jgKA"
      },
      "source": [
        "# standardadize feature data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler: MinMaxScaler = MinMaxScaler()\n",
        "features_std = scaler.fit_transform(feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkx27dUwkgbV"
      },
      "source": [
        "convert to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr4aB5xZ-CFy"
      },
      "source": [
        "# hyperparameters\n",
        "DEVICE: torch.device = torch.device('cuda')\n",
        "LEARNING_RATE: float = 1e-3\n",
        "NUM_EPOCH: int = 300\n",
        "batch_size: int = 17\n",
        "number_folds: int = 5  # fold k times"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7BdwWjUQ7TA",
        "outputId": "4112960d-c105-4ee2-be67-d373686ad501"
      },
      "source": [
        "X = torch.tensor(features_std, device=DEVICE)\n",
        "target = torch.tensor(performance_10session.values, device=DEVICE)\n",
        "print(X.shape)\n",
        "print(target.shape)\n",
        "train_dataset = TensorDataset(X,target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([170, 18])\n",
            "torch.Size([170, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am0-5jKR2r1Q"
      },
      "source": [
        "# Split to train, validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O4jDUxiyVjC"
      },
      "source": [
        "def load_data_kfold(data, batch_size, k, n):\n",
        "    # This function using functions in preprocessing.py to build dataset,\n",
        "    # and then randomly split dataset with a fixed random seed.\n",
        "\n",
        "    l = len(data)\n",
        "    shuffle_dataset = True\n",
        "    random_seed = 0  # fixed random seed (42)\n",
        "    indices = list(range(l))\n",
        "\n",
        "    if shuffle_dataset:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)  # shuffle\n",
        "    # Collect indexes of samples for validation set.\n",
        "    val_indices = indices[int(l / k) * n:int(l / k) * (n + 1)]\n",
        "    # Collect indexes of samples for train set. Here the logic is that a sample\n",
        "    # cannot in train set if already in validation set\n",
        "    train_indices = list(set(indices).difference(set(val_indices)))\n",
        "    # build Sampler\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
        "    train_loader = DataLoader(data, batch_size=batch_size, sampler=train_sampler)  # build dataloader for train set\n",
        "    validation_loader = DataLoader(data, batch_size=batch_size, sampler=valid_sampler)  # build dataloader for validate set\n",
        "    return train_loader, validation_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKNRL6P72uKJ"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvtQpFvAyUKQ"
      },
      "source": [
        "# create MLP with one hidden layer\n",
        "class MLPnet(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(MLPnet, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.dense1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(.5)\n",
        "    self.dense2 = nn.Linear(hidden_dim, output_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = x.view(x.size(0), self.input_dim)\n",
        "    x = self.dense1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    y2 = self.dense2(x)\n",
        "    return y2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21jY7Nu1nN3G"
      },
      "source": [
        "class MLP_2hiddenlayer(torch.nn.Module):\n",
        "  def __init__(self, input_dim, n1, n2, output_dim):\n",
        "    super(MLP_2hiddenlayer, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.dense1 = nn.Linear(input_dim, n1)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(.5)\n",
        "    self.dense2 = nn.Linear(n1, n2)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.dense3 = nn.Linear(n2, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.size(0), self.input_dim)\n",
        "    x = self.dense1(x)\n",
        "    y1 = self.relu1(x)\n",
        "    y1 = self.dropout(y1)\n",
        "    y2 = self.dense2(y1)\n",
        "    y2 = self.relu2(y2)\n",
        "    y3 = self.dense3(y2)\n",
        "    return y3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-1_jcj5d68Y"
      },
      "source": [
        "class MLP_3hiddenlayer(torch.nn.Module):\n",
        "  def __init__(self, input_dim, n1, n2, n3, output_dim):\n",
        "    super(MLP_3hiddenlayer, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.dense1 = nn.Linear(input_dim, n1)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.dense2 = nn.Linear(n1, n2)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.dense3 = nn.Linear(n2, n3)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.dense4 = nn.Linear(n3, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.size(0), self.input_dim)\n",
        "    x = self.dense1(x)\n",
        "    y1 = self.relu1(x)\n",
        "    y2 = self.dense2(y1)\n",
        "    y2 = self.relu2(y2)\n",
        "    y3 = self.dense3(y2)\n",
        "    y3 = self.relu3(y3)\n",
        "    y4 = self.dense4(y3)\n",
        "    return y4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWBgtCgSJiIe"
      },
      "source": [
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yka8-lvSOlaJ"
      },
      "source": [
        "# train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pypQj7NSL6jT"
      },
      "source": [
        "# base linear regression model\n",
        "model=linearRegression(18, 10).to(DEVICE).to(torch.double)\n",
        "mse_loss = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(NUM_EPOCH):\n",
        "    inputs = X\n",
        "    labels = target\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = mse_loss(outputs, labels)\n",
        "    print(loss)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXnVC4AAmej4"
      },
      "source": [
        "train_loss_allfold = []\n",
        "valid_loss_allfold = []\n",
        "for n in range(number_folds):\n",
        "    # Load data for current fold\n",
        "    train_loader, validation_loader = load_data_kfold(train_dataset, batch_size, number_folds, n)\n",
        "    print(\"\\nNo.\", n, \"Fold\")\n",
        "\n",
        "    # model = MLPnet(18,10,10).to(DEVICE).to(torch.double)\n",
        "    model = MLP_2hiddenlayer(18,20,12,10).to(DEVICE).to(torch.double)\n",
        "    # model = MythirdNetwork(18,12,10,6,10).to(DEVICE).to(torch.double)\n",
        "    # model = LinearRegressionModel().to(DEVICE).to(torch.double) \n",
        "  \n",
        "    #loss function and optimizer\n",
        "    mse_loss = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # weight_decay = 0.001\n",
        "\n",
        "    # Start training for current fold\n",
        "    valid_losses = []\n",
        "    train_losses = []\n",
        "    for epoch in range(NUM_EPOCH):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        # print('train_loader length={}, batch_size={}'.format(len(train_loader.dataset), train_loader.batch_size))\n",
        "        num_batch = len(train_loader)\n",
        "\n",
        "        train_loss = 0\n",
        "        for batch_id, (batch_x, batch_y) in enumerate(train_loader):\n",
        "            y_pred = model(batch_x)\n",
        "\n",
        "            loss = mse_loss(y_pred, batch_y)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            elapsed_time = time.time() - start_time\n",
        "            elapsed_min = int(elapsed_time / 60)\n",
        "            elapsed_sec = elapsed_time - 60 * elapsed_min\n",
        "\n",
        "            # print('\\rEpoch:{} Batch:{}/{} Loss:{:.4f} Time:{}m{:.2f}s\\n'.format(epoch + 1, batch_id, num_batch, loss.item(), elapsed_min, elapsed_sec), end='')\n",
        "        \n",
        "        #print(\"am i running?\")\n",
        "        train_loss /= num_batch\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        best_loss = 0.6 # np.inf\n",
        "        num_batch = len(validation_loader)\n",
        "\n",
        "        for batch_id, (batch_x, batch_y) in enumerate(validation_loader):\n",
        "            y_pred = model(batch_x)\n",
        "            loss = mse_loss(y_pred, batch_y)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "        valid_loss /= num_batch\n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        #save model when validation loss is minimum\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'mlp__regression.model')  \n",
        "\n",
        "        # print('Valid Loss:{:.4f}'.format(valid_loss))\n",
        "    \n",
        "    train_loss_allfold.append(train_losses)\n",
        "    valid_loss_allfold.append(valid_losses)\n",
        "        #plot\n",
        "    fig, ax = plt.subplots(figsize=(7,5))\n",
        "    ax.plot(train_losses, 'blue')\n",
        "    ax.plot(valid_losses, 'red')\n",
        "    ax.set_title('Training loss curves: fold' + str(n))\n",
        "    ax.set_ylim(0,max(valid_losses)+2)\n",
        "    ax.set_xlabel('Epochs')\n",
        "    ax.set_ylabel('Mean Squared Error')\n",
        "    ax.legend(['Train','Validation'])\n",
        "\n",
        "    print('minimum validation loss is {:.4f}'.format(min(valid_losses)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y52YfLZujn72"
      },
      "source": [
        "df_train_loss = pd.DataFrame(train_loss_allfold).T\n",
        "df_valid_loss = pd.DataFrame(valid_loss_allfold).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiI7cV8xnwNR"
      },
      "source": [
        "# training curves average all folds\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "df = [df_train_loss, df_valid_loss]\n",
        "colors = ['blue', 'red']\n",
        "for i in range(2):\n",
        "  df_mean = df[i].mean(1)\n",
        "  df_sd = df[i].std(1)\n",
        "  t = pd.DataFrame({'mean': df_mean, 'sd': df_sd})\n",
        "  x = range(NUM_EPOCH)\n",
        "  y = t['mean']\n",
        "  yerr = t['sd']\n",
        "  # ci = 1.96 * np.std(y)/np.mean(y)\n",
        "  label = str(i)\n",
        "  ax.plot(x, y, color = colors[i],\n",
        "              label=label, linewidth=4)\n",
        "  ax.fill_between(x, (y+yerr), (y-yerr), color='b', alpha=.1)\n",
        "  ax.set_xlabel('Epochs', fontsize=22)\n",
        "  ax.set_ylabel('Mse loss', fontsize=22)\n",
        "  # ax.set_title('cluster_using max, slope and sd', fontsize=28)\n",
        "  # ax.set_xlim(1,501)\n",
        "  ax.set_yticks(np.arange(1, 14, 1))\n",
        "ax.tick_params(labelsize=20)\n",
        "ax.legend(['Train','Validation'], fontsize=20)\n",
        "# ax.legend()\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWPjK-Be7zwk"
      },
      "source": [
        "# get sample data in each fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKqJrrWQBPQC"
      },
      "source": [
        "def get_sampled_dataframe(sampled_data_loader, part):\n",
        "  sampled_data_set = sampled_data_loader.dataset.tensors[part].cpu()\n",
        "  sampled_index = list(iter(sampled_data_loader.sampler))\n",
        "  return pd.DataFrame(sampled_data_set.numpy()).loc[sampled_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR9woRFpD7fs"
      },
      "source": [
        "for n in range(5):\n",
        "  train_loader, valid_loader = load_data_kfold(train_dataset, 5000, number_folds, n)\n",
        "  df_valid_target = get_sampled_dataframe(valid_loader, 1)\n",
        "  fig, ax = plt.subplots(figsize=(8,6))\n",
        "  x = df_valid_target.columns\n",
        "  ax.set_title('Traning trajectory')\n",
        "  for index, row in df_valid_target.iterrows():\n",
        "    y = row\n",
        "    ax.plot(x, y, linewidth=2)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LEVcYHv7jBP"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJC_OBPGpdyL",
        "outputId": "eb9be3fa-c268-4a7f-ad8b-00f3fd655c72"
      },
      "source": [
        "model.load_state_dict(torch.load('mlp__regression.model'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MkAUFkw5_cn"
      },
      "source": [
        "model.to(DEVICE).to(torch.double)\n",
        "y_pred = model(X)\n",
        "y_pred = pd.DataFrame(y_pred.data.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHHhXLQW-jdQ"
      },
      "source": [
        "# correlation scatter plots\n",
        "for i in range (10):\n",
        "  fig, ax = plt.subplots(figsize=(3,3))\n",
        "  y = y_pred.iloc[:,i]\n",
        "  x = performance_10session.iloc[:,i]\n",
        "  ax.scatter(x,y,c='blue')\n",
        "# ax.legend(fontsize=24, loc=4)\n",
        "  ax.set_ylim(ymin=1, ymax=8)\n",
        "  ax.set_xlim(xmin=1, xmax=8)\n",
        "  ax.set_xlabel('True value', fontsize=12)\n",
        "  ax.set_ylabel('Predicted value', fontsize=12)\n",
        "  ax.tick_params(labelsize=12)\n",
        "  correlation = 'R={:.3f}'.format(x.corr(y))\n",
        "  ax.set_title('Session '+ str(i+1) +':' + correlation, loc='right', fontsize=12)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9P98oUjPQTD"
      },
      "source": [
        "# histograms\n",
        "for i in range (10):\n",
        "  fig, ax = plt.subplots(figsize=(3,3))\n",
        "  ax.hist(y_pred.iloc[:,i],histtype='stepfilled', color='blue', label='Prediction')\n",
        "  ax.hist(performance_10session.iloc[:,i],histtype='step', color='dimgray', label='Target')\n",
        "  # ax.set_xlabel('Value', fontsize=12)\n",
        "  # ax.set_ylabel('Count', fontsize=12)\n",
        "  ax.tick_params(labelsize=12)\n",
        "  ax.set_title('Session '+ str(i+1), fontsize=12)\n",
        "  # ax.legend(fontsize=10)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goGPKbSF-DW6"
      },
      "source": [
        "# explain the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIvJGC1biuwY"
      },
      "source": [
        "!pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ytV-4Xmhu3h"
      },
      "source": [
        "import shap\n",
        "features = torch.tensor(features_std, device=DEVICE)\n",
        "explainer=shap.DeepExplainer(model, features)\n",
        "shap_values = explainer.shap_values(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh9CnSVnlKbS"
      },
      "source": [
        "import pickle\n",
        "with open(path.join(work_dir, \"shap_values(10,6,10)\"), mode='wb') as f:\n",
        "  pickle.dump(shap_values, f)\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xss-lP-3siex"
      },
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value[9], shap_values[9], features_std, feature_name_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOlQtuOkrcL3"
      },
      "source": [
        "shap.summary_plot(shap_values, features_std, feature_names=feature_name_list, cmap='BuPu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsXTWTFp8IMs"
      },
      "source": [
        "shap.summary_plot(shap_values[8], features_std, feature_names=feature_name_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}